import math
import argparse
import itertools

# subset diamond results, only keeping best bitscore hits per read
def subset_reads():
	results = {}
	
	for i in open(args.d):
		tmp = i.strip().split('\t')
		read,aln_len,bitscore = tmp[0],int(tmp[3]),float(tmp[11])
		if aln_len >= 30:
			if read not in results:
				results[read] = {bitscore:[tmp]}
			elif bitscore in results[read]:
				results[read][bitscore].append(tmp)
	
	return results

def build_taxonomy_dicts():
	# build dictionaries for looking up taxonomic lineages, ID's and ranks
	nodes = {i.strip().split('\t')[0]:i.strip().split('\t')[1] for i in open(args.path+'/nodes')}
	names = {i.strip().split('\t')[1].upper():i.strip().split('\t')[0] for i in open(args.path+'/names')}
	
	fullLineage = {}
	for i in open(args.path+'/fullnamelineage.dmp'):
		tmp = i.strip().split('\t|\t')
		id  = tmp[0].strip()
		name = tmp[1].strip().upper()
		lineage = tmp[2].strip('\t|').upper().strip() + ' ' + name
		fullLineage[id] = lineage
	
	# build dictionaries for looking up taxonomic lineages by uniref ID and protein lengths by marker gene group ID
	uniref2lineage = {}
	busco2protlen = {}
	
	with open(args.path+'/euk_functions.txt') as f:
		next(f)
		for i in f:
			tmp = i.strip().split('\t')
			uniref = tmp[0]
			lineage = tmp[3].upper()
			uniref2lineage[uniref] = lineage
	
	for i in open(args.path+'/marker_gene_group_lens.txt'):
		tmp = i.strip().split('\t')
		MG_group = tmp[0]
		MG_MSA_len = float(tmp[1])
		busco2protlen[MG_group] = MG_MSA_len
	
	return nodes,names,fullLineage,uniref2lineage,busco2protlen


def build_MG_Classifiers():
	# dictionary of marker genes reads aligned to
	classifiers = {i.strip().split('\t')[1]:{} for i in open(args.d)}
	print "Number of candidate marker genes found in sample: ",len(classifiers)

	# collect uniref to marker gene group mappings and the structure of gaps for each
	# uniref per their multiple sequence alignment with marker gene groups
	marker_gene_groups = {}
	marker_gene_indices = {}
	
	for i in open(args.path+'/global_msa_indices.txt'):
		tmp = i.strip().split('\t')
		uniref = tmp[0]
		if uniref in classifiers:
			F_name = tmp[1]
			F_gap_starts = map(int,tmp[2].split(','))
			F_gap_lens = map(int,tmp[3].split(','))
			G_name = tmp[4]
			G_gap_starts = map(int,tmp[5].split(','))
			G_gap_lens = map(int,tmp[6].split(','))
			S_name = tmp[7]
			S_gap_starts = map(int,tmp[8].split(','))
			S_gap_lens = map(int,tmp[9].split(','))
			marker_gene_groups[F_name] = 0
			marker_gene_groups[G_name] = 0
			marker_gene_groups[S_name] = 0
			marker_gene_indices[uniref] = {F_name:[F_gap_starts,F_gap_lens],G_name:[G_gap_starts,G_gap_lens],S_name:[S_gap_starts,S_gap_lens]}
	
	print "Extracted MSA groups and coordinates!!!"
	
	# collect coefficients of spline and logistic functions, as well as classification power by region, per marker gene group
	# format of slopes file
	# Marker_gene_group     Knots   A       B       C       D       LR_slopes       LR_y_ints       Classification_power
	for h,i in enumerate(open(args.path+'/slopes2.threshold.logistic.txt')):
		if h == 0: continue
		tmp = i.strip().split('\t')
		marker_gene_group = tmp[0]
		knots = map(float,tmp[1].split(','))
		A = map(float,tmp[2].split(','))
		B = map(float,tmp[3].split(','))
		C = map(float,tmp[4].split(','))
		D = map(float,tmp[5].split(','))
		LR_slopes = [float(i) if i != 'NA' else 'NA' for i in tmp[6].split(',')]
		LR_y_ints = [float(i) if i != 'NA' else 'NA' for i in tmp[7].split(',')]
		Classification_power = map(float,tmp[8].split(','))
		if marker_gene_group in marker_gene_groups:
			marker_gene_groups[marker_gene_group] = [knots,A,B,C,D,LR_slopes,LR_y_ints,Classification_power]
	
	return marker_gene_groups,marker_gene_indices


# transforms the local start position of the read mapped to the marker gene
# to the global start position in the MSA of the taxonomic group for the marker gene
def adjust_start(start,gaps):
	for gap_start,gap_len in zip(*gaps):
		if start >= gap_start:
			start += gap_len
	return start

# takes the coefficients of the spline polynomial and logistic regression
# models, as well as the classification power of the given region, and returns the
# probability that the aligned read comes from that taxonomic group, as well as the
# classification power of the region
def classify(dist_from_knot,qslope,A,B,C,D,LR_slope,LR_y_int,Classification_power):
	if LR_slope <= 0:
		return 0,Classification_power
	decision_threshold = ((A*dist_from_knot)**3)+((B*dist_from_knot)**2)+(C*dist_from_knot)+D
	if LR_slope == 'NA':
		if qslope >= decision_threshold:
			return 1,Classification_power
		else:
			return 0,Classification_power
	else:
		dist_from_threshold_boundary = qslope - decision_threshold
		probability = 1/(1+(math.exp(-1*(LR_y_int+LR_slope*dist_from_threshold_boundary))))
		return probability,Classification_power


# returns the lowest common ancestor of a list of NCBI taxonomic lineages
def LCA(lineages):
	lineages = map(lambda x: x.split(';'),lineages)
#	nr_lineages = []
#	for a, b in itertools.combinations(lineages, 2): # if there is best hit tie between different ranks of same lineage, prefer more specific rank
#		if len(set(a) | set(b)) == len(max(a,b,key=len)):
#			nr_lineages.append(max(a,b,key=len))
#		else:
#			nr_lineages.append(a)
#			nr_lineages.append(b)
	new_lineage = [i[0].strip() for i in zip(*lineages) if len(set(i)) == 1 if '' not in i]
	return new_lineage


def classify_singleton(proteins,out):
	query = proteins[0][0]
	uniref = proteins[0][1]
	if uniref not in marker_gene_indices: return None
	aln_len = int(proteins[0][3])
	qstart = int(proteins[0][8])
	bitscore = float(proteins[0][11])
	qslope = bitscore/aln_len
	results = {}
	for marker_gene_group,gaps in marker_gene_indices[uniref].items():
		adjusted_start = adjust_start(qstart,gaps)
		if marker_gene_groups[marker_gene_group] == 0: continue
		for knot,A,B,C,D,LR_slope,LR_y_int,Classification_power in zip(*marker_gene_groups[marker_gene_group]):
			dist_from_knot = abs(adjusted_start - knot)
			if dist_from_knot <= 10:
				probability,classification_power_of_region = classify(dist_from_knot,qslope,A,B,C,D,LR_slope,LR_y_int,Classification_power)
				taxa_rank = nodes[marker_gene_group.split('_')[1]]
				results[taxa_rank]= [marker_gene_group,probability,classification_power_of_region]
				break
	if results == {}: return None
	for rank in ['species','genus','family']:
		if rank in results:
			out.write(query+'\t'+uniref+'\t'+results[rank][0]+'\t'+str(results[rank][1])+'\t'+str(results[rank][2])+'\n')
			break


def classify_multimapped(proteins,out):
	taxaName = False
	lineages = LCA([uniref2lineage[i[1]] for i in proteins])
	query = proteins[0][0]
	uniref = proteins[0][1]
	if uniref not in marker_gene_indices: return None
	aln_len = int(proteins[0][3])
	qstart = int(proteins[0][8])
	bitscore = float(proteins[0][11])
	for i in reversed(lineages):
		rank = nodes[names[i]]
		if rank in ['species','genus','family']:
			for k in marker_gene_indices[uniref].keys():
				if k != '0':
					if nodes[k.split('_')[1]] == rank:
						taxaName = k
						break
			break
	if taxaName == False: return None
	qslope = bitscore/aln_len
	results = {}
	gaps = marker_gene_indices[uniref][taxaName]
	adjusted_start = adjust_start(qstart,gaps)
	if marker_gene_groups[taxaName] == 0: return None
	for knot,A,B,C,D,LR_slope,LR_y_int,Classification_power in zip(*marker_gene_groups[taxaName]):
		dist_from_knot = abs(adjusted_start - knot)
		if dist_from_knot <= 10:
			probability,classification_power_of_region = classify(dist_from_knot,qslope,A,B,C,D,LR_slope,LR_y_int,Classification_power)
			taxa_rank = nodes[taxaName.split('_')[1]]
			results[taxa_rank]= [taxaName,probability,classification_power_of_region]
			break
	if results == {}: return None
	for rank in ['species','genus','family']:
		if rank in results:
			out.write(query+'\t'+uniref+'\t'+results[rank][0]+'\t'+str(results[rank][1])+'\t'+str(results[rank][2])+'\n')
			break

# parse user input argumets
parser = argparse.ArgumentParser()
parser.add_argument("-d", help="diamond output file")
parser.add_argument("-path", help="path to data directory i.e. /usr/local/protist_pipeline/data/")
parser.add_argument("-th", help="Probability cutoff for reporting results")
args = parser.parse_args()

# subset diamond results only keeping the highest bitscore alignment(s) per read
diamond_subset = subset_reads()
print "Filtered diamond output!!!"

# build dictionaries with taxonomic nomenclature
nodes,names,fullLineage,uniref2lineage,busco2protlen = build_taxonomy_dicts()
print "Extracted taxonomy information!!!"

# collect read file information --> average read length and number of reads
for h,i in enumerate(open('read_file_info.txt')):
	if h == 0: read_count = float(i.strip())
	elif h == 1: av_read_len = float(i.strip())

# collect marker gene and classifier information
marker_gene_groups,marker_gene_indices = build_MG_Classifiers()
print "Extracted marker gene classifiers!!!"

# classify each read per marker gene group it aligns to
with open('reads_classified.txt','w') as out:
	for read,v in diamond_subset.items():
		for bitscore,proteins in v.items():
			if len(proteins) == 1:
				classify_singleton(proteins,out)
			elif len(proteins) > 1:
				classify_multimapped(proteins,out)

print "Finished classifying individual reads!!! Aggregating results..."

taxa_counts = {}
best_probs = {}

with open('Taxonomic_report.txt','w') as out:
	for i in open('reads_classified.txt'):
		tmp = i.strip().split('\t')
		query = tmp[0]
		uniref = tmp[1]
		taxaID = tmp[2].split('_')[1]
		lineage_trimmed = fullLineage[taxaID]
		r_prob = float(tmp[3])
		classification_power = float(tmp[4])
		r_prob = r_prob*classification_power
		if r_prob >= (float(args.th)):
			if query not in best_probs:
				best_probs[query] = [lineage_trimmed]
			else:
				best_probs[query].append(lineage_trimmed)
	for query,lines in best_probs.items():
		lines = list(set(lines))
		if len(lines) > 1:
			lca = LCA(lines)
		else:
			lca = map(lambda x:x.strip(),lines[0].split(';'))
		if lca == []: continue
		line = ''
		for i in lca:
			if i == '': continue
			line += i+';'
			if line not in taxa_counts:
				taxa_counts[line] = 1
			else:
				taxa_counts[line] += 1
	for k,v in sorted(taxa_counts.items()):
		relative_abundance = str((v*av_read_len)/(busco2protlen[names[k.split(';')[-2]]]*read_count))
		out.write(k+'\t'+str(v)+'\t'+relative_abundance+'\n')


print "Taxonomic report has successfully been written!!! Analysis completed successfully!"







